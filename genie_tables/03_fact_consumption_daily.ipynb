{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACT_CONSUMPTION_DAILY - Daily Consumption Fact Table\n",
    "\n",
    "Daily grain fact table containing consumption and revenue metrics for the Genie Space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Table Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Drop table if exists (uncomment if needed)\n",
    "-- DROP TABLE IF EXISTS ankit_yadav.demo.fact_consumption_daily;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS ankit_yadav.demo.fact_consumption_daily (\n",
    "  consumption_date DATE NOT NULL COMMENT 'Date of consumption',\n",
    "  account_id STRING NOT NULL COMMENT 'Foreign key to dim_accounts',\n",
    "  workspace_id STRING COMMENT 'Databricks workspace identifier',\n",
    "  platform STRING COMMENT 'Cloud platform (AWS, Azure, GCP)',\n",
    "  sku STRING COMMENT 'Product SKU (JOBS, SQL, SERVING, etc.)',\n",
    "  account_name STRING COMMENT 'Customer account name',\n",
    "  account_executive STRING COMMENT 'Account Executive name',\n",
    "  account_executive_manager STRING COMMENT 'AE Manager name',\n",
    "  workspace_name STRING COMMENT 'Workspace display name',\n",
    "  list_price_per_dbu FLOAT COMMENT 'List price per DBU',\n",
    "  revenue_dollars FLOAT COMMENT 'Revenue in dollars',\n",
    "  dbus_consumed FLOAT COMMENT 'Databricks Units consumed',\n",
    "  load_timestamp TIMESTAMP COMMENT 'ETL load timestamp'\n",
    ")\n",
    "COMMENT 'Daily grain fact table containing consumption and revenue metrics';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Insert Demo Data\n",
    "\n",
    "Generate 90 days of consumption data for all demo accounts across multiple SKUs and workspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Clear existing demo data\n",
    "DELETE FROM ankit_yadav.demo.fact_consumption_daily WHERE account_id LIKE 'DEMO%';\n",
    "\n",
    "-- Generate 90 days of daily consumption data\n",
    "-- Using a CTE to create date range and cross join with accounts/SKUs\n",
    "\n",
    "WITH date_range AS (\n",
    "  SELECT EXPLODE(SEQUENCE(\n",
    "    DATE_SUB(CURRENT_DATE(), 90),\n",
    "    CURRENT_DATE(),\n",
    "    INTERVAL 1 DAY\n",
    "  )) as consumption_date\n",
    "),\n",
    "accounts AS (\n",
    "  SELECT * FROM ankit_yadav.demo.dim_accounts WHERE account_id LIKE 'DEMO%'\n",
    "),\n",
    "skus AS (\n",
    "  SELECT 'JOBS_COMPUTE' as sku, 0.40 as list_price, 'Production' as workspace_suffix UNION ALL\n",
    "  SELECT 'JOBS_COMPUTE' as sku, 0.40 as list_price, 'Development' as workspace_suffix UNION ALL\n",
    "  SELECT 'SQL_COMPUTE' as sku, 0.55 as list_price, 'Analytics' as workspace_suffix UNION ALL\n",
    "  SELECT 'ALL_PURPOSE_COMPUTE' as sku, 0.55 as list_price, 'Development' as workspace_suffix UNION ALL\n",
    "  SELECT 'MODEL_SERVING' as sku, 0.07 as list_price, 'Production' as workspace_suffix UNION ALL\n",
    "  SELECT 'DELTA_LIVE_TABLES' as sku, 0.36 as list_price, 'Production' as workspace_suffix\n",
    "),\n",
    "base_consumption AS (\n",
    "  SELECT \n",
    "    d.consumption_date,\n",
    "    a.account_id,\n",
    "    CONCAT('WS-', a.account_id, '-', s.workspace_suffix) as workspace_id,\n",
    "    CASE \n",
    "      WHEN a.account_region LIKE '%California%' THEN 'AWS'\n",
    "      WHEN a.account_region LIKE '%Pacific%' THEN 'AZURE'\n",
    "      ELSE CASE WHEN RAND() > 0.5 THEN 'AWS' ELSE 'AZURE' END\n",
    "    END as platform,\n",
    "    s.sku,\n",
    "    a.account_name,\n",
    "    a.account_executive_name as account_executive,\n",
    "    a.account_executive_manager,\n",
    "    CONCAT(a.account_name, ' - ', s.workspace_suffix) as workspace_name,\n",
    "    s.list_price as list_price_per_dbu,\n",
    "    -- Base DBU consumption varies by account size and day of week\n",
    "    ROUND(\n",
    "      (\n",
    "        -- Base consumption by account (larger accounts consume more)\n",
    "        CASE \n",
    "          WHEN a.account_id IN ('DEMO003', 'DEMO008') THEN 800  -- Large accounts\n",
    "          WHEN a.account_id IN ('DEMO001', 'DEMO002', 'DEMO007', 'DEMO010') THEN 500  -- Medium\n",
    "          ELSE 250  -- Smaller accounts\n",
    "        END\n",
    "        -- SKU multiplier\n",
    "        * CASE \n",
    "          WHEN s.sku = 'JOBS_COMPUTE' THEN 1.5\n",
    "          WHEN s.sku = 'SQL_COMPUTE' THEN 1.2\n",
    "          WHEN s.sku = 'ALL_PURPOSE_COMPUTE' THEN 0.8\n",
    "          WHEN s.sku = 'MODEL_SERVING' THEN 2.0\n",
    "          ELSE 0.6\n",
    "        END\n",
    "        -- Day of week effect (lower on weekends)\n",
    "        * CASE \n",
    "          WHEN DAYOFWEEK(d.consumption_date) IN (1, 7) THEN 0.3\n",
    "          ELSE 1.0\n",
    "        END\n",
    "        -- Random variation (+/- 30%)\n",
    "        * (0.7 + RAND() * 0.6)\n",
    "        -- Growth trend (newer dates have slightly more consumption)\n",
    "        * (1 + (DATEDIFF(d.consumption_date, DATE_SUB(CURRENT_DATE(), 90)) / 300.0))\n",
    "      ), 2\n",
    "    ) as dbus_consumed\n",
    "  FROM date_range d\n",
    "  CROSS JOIN accounts a\n",
    "  CROSS JOIN skus s\n",
    "  -- Not all accounts have all SKUs - filter to realistic combinations\n",
    "  WHERE NOT (\n",
    "    (a.account_id IN ('DEMO010', 'DEMO012') AND s.sku = 'MODEL_SERVING') OR\n",
    "    (a.account_id IN ('DEMO005', 'DEMO011') AND s.sku = 'DELTA_LIVE_TABLES')\n",
    "  )\n",
    ")\n",
    "INSERT INTO ankit_yadav.demo.fact_consumption_daily\n",
    "SELECT \n",
    "  consumption_date,\n",
    "  account_id,\n",
    "  workspace_id,\n",
    "  platform,\n",
    "  sku,\n",
    "  account_name,\n",
    "  account_executive,\n",
    "  account_executive_manager,\n",
    "  workspace_name,\n",
    "  list_price_per_dbu,\n",
    "  ROUND(dbus_consumed * list_price_per_dbu, 2) as revenue_dollars,\n",
    "  dbus_consumed,\n",
    "  CURRENT_TIMESTAMP() as load_timestamp\n",
    "FROM base_consumption;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Sample data\n",
    "SELECT * FROM ankit_yadav.demo.fact_consumption_daily \n",
    "WHERE account_id = 'DEMO001'\n",
    "ORDER BY consumption_date DESC, sku\n",
    "LIMIT 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Daily totals by account\n",
    "SELECT \n",
    "  account_name,\n",
    "  account_executive_manager,\n",
    "  COUNT(DISTINCT consumption_date) as days_with_consumption,\n",
    "  ROUND(SUM(revenue_dollars), 2) as total_revenue,\n",
    "  ROUND(SUM(dbus_consumed), 2) as total_dbus,\n",
    "  ROUND(AVG(revenue_dollars), 2) as avg_daily_revenue\n",
    "FROM ankit_yadav.demo.fact_consumption_daily\n",
    "GROUP BY account_name, account_executive_manager\n",
    "ORDER BY total_revenue DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Revenue by SKU\n",
    "SELECT \n",
    "  sku,\n",
    "  COUNT(*) as record_count,\n",
    "  ROUND(SUM(revenue_dollars), 2) as total_revenue,\n",
    "  ROUND(SUM(dbus_consumed), 2) as total_dbus,\n",
    "  ROUND(AVG(list_price_per_dbu), 2) as avg_list_price\n",
    "FROM ankit_yadav.demo.fact_consumption_daily\n",
    "GROUP BY sku\n",
    "ORDER BY total_revenue DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Record count summary\n",
    "SELECT \n",
    "  COUNT(*) as total_records,\n",
    "  COUNT(DISTINCT account_id) as unique_accounts,\n",
    "  COUNT(DISTINCT consumption_date) as unique_dates,\n",
    "  COUNT(DISTINCT sku) as unique_skus,\n",
    "  MIN(consumption_date) as earliest_date,\n",
    "  MAX(consumption_date) as latest_date,\n",
    "  ROUND(SUM(revenue_dollars), 2) as total_revenue\n",
    "FROM ankit_yadav.demo.fact_consumption_daily;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
