{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae2ef0d2-0c53-45d3-9b2f-281ac1bcd43d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mosaic AI Agent Framework: Author and deploy a multi-agent system with Genie and Serving Endpoints\n",
    "\n",
    "This notebook demonstrates how to build a multi-agent system using Mosaic AI Agent Framework and [LangGraph](https://blog.langchain.dev/langgraph-multi-agent-workflows/), where [Genie](https://www.databricks.com/product/ai-bi/genie) is one of the agents.\n",
    "In this notebook, you:\n",
    "1. Author a multi-agent system using LangGraph.\n",
    "1. Wrap the LangGraph agent with MLflow `ResponsesAgent` to ensure compatibility with Databricks features.\n",
    "1. Manually test the multi-agent system's output.\n",
    "1. Log and deploy the multi-agent system.\n",
    "\n",
    "This example is based on [LangGraph documentation - Multi-agent supervisor example](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/agent_supervisor.md)\n",
    "\n",
    "## Why use a Genie agent?\n",
    "\n",
    "Multi-agent systems consist of multiple AI agents working together, each with specialized capabilities. As one of those agents, Genie allows users to interact with their structured data using natural language. Unlike SQL functions which can only run pre-defined queries, Genie has the flexibility to create novel queries to answer user questions.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Address all `TODO`s in this notebook.\n",
    "- Create a Genie Space, see Databricks documentation ([AWS](https://docs.databricks.com/aws/genie/set-up) | [Azure](https://learn.microsoft.com/azure/databricks/genie/set-up))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad5bdf5-8ab6-40ad-8b7f-71589b07dde4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Databricks package installation and Python restart"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -qqq mlflow-skinny[databricks] databricks-langchain databricks-agents uv langgraph-supervisor==0.0.31 langchain>=1.0.2 deepagents\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "700a1a67-c88e-4d46-8a8d-0467faa2babb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf5a8a86-87b7-4b87-a35c-7ecf70619f6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.7\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d402207-8884-456d-8e29-dce582e48dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Define the multi-agent system\n",
    "\n",
    "Create a multi-agent system in LangGraph using a supervisor agent node with one or more of the following subagents:\n",
    "- **GenieAgent**: A LangChain runnable that allows you to easily interact with your Genie Space to query structured data.\n",
    "- **Custom serving agent**: An agent that is already hosted as an existing endpoint on Databricks.\n",
    "- **In-code tool-calling agent**: An agent that calls Unity Catalog function tools, defined within this notebook. This example uses `system.ai.python_exec`, but for examples of other tools you can add to your agents, see Databricks documentation ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-tool) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/agent-tool)).\n",
    "\n",
    "The supervisor agent is responsible for creating and routing tool calls to each of your subagents, passing only the context necessary. You can modify this behavior and pass along the entire message history if desired. See the [LangGraph docs](https://langchain-ai.github.io/langgraph/reference/supervisor/) for more information.\n",
    "\n",
    "#### Write agent code to file\n",
    "\n",
    "Define the agent code in a single cell below. This lets you write the agent code to a local Python file, using the `%%writefile` magic command, for subsequent logging and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a89ad7a6-599d-46a9-9f09-b149e4651c87",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Agent State and Tools for Structured Task Planning"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing agent_dev.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agent_dev.py\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Any, Generator\n",
    "from uuid import uuid4\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import TodoListMiddleware\n",
    "from langchain.agents.middleware.summarization import SummarizationMiddleware\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    ")\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from deepagents.middleware.filesystem import FilesystemMiddleware, FilesystemState\n",
    "from deepagents.middleware.patch_tool_calls import PatchToolCallsMiddleware\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "\n",
    "########################################\n",
    "# Formatting Helper Functions\n",
    "########################################\n",
    "\n",
    "def remove_file_references(content: str) -> str:\n",
    "    \"\"\"Remove references to virtual file operations from agent responses.\n",
    "\n",
    "    Strips mentions of file operations (write_file, read_file, ls) that are\n",
    "    implementation details not relevant to end users.\n",
    "    \"\"\"\n",
    "    if not content:\n",
    "        return content\n",
    "\n",
    "    patterns = [\n",
    "        r\"I(?:'ve| have) saved.*?to [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"I(?:'ll| will) save.*?to [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"Let me save.*?to [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"I(?:'ve| have) written.*?to [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"Saved to [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"Writing to [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"I(?:'ll| will) write.*?to [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"Saving.*?to [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"Reading from [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"I(?:'ve| have) read.*?from [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"Let me read.*?from [\\w_\\-\\./]+\\.\\w+\",\n",
    "        r\"The file [\\w_\\-\\./]+\\.\\w+ contains\",\n",
    "        r\"From [\\w_\\-\\./]+\\.\\w+:\",\n",
    "        r\"I(?:'ve| have) saved.*?to /large_tool_results/[\\w_\\-\\./]+\",\n",
    "        r\"The (?:full )?results? (?:were|was|has been) (?:automatically )?saved to /large_tool_results/[\\w_\\-\\./]+\",\n",
    "    ]\n",
    "\n",
    "    cleaned = content\n",
    "    for pattern in patterns:\n",
    "        cleaned = re.sub(pattern, \"\", cleaned, flags=re.IGNORECASE)\n",
    "\n",
    "    cleaned = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def apply_format_template(content: str, state: dict) -> str:\n",
    "    \"\"\"Apply consistent formatting to final response.\"\"\"\n",
    "    return content.strip()\n",
    "\n",
    "\n",
    "########################################\n",
    "# Configuration Models\n",
    "########################################\n",
    "\n",
    "GENIE = \"genie\"\n",
    "\n",
    "\n",
    "class ServedSubAgent(BaseModel):\n",
    "    endpoint_name: str\n",
    "    name: str\n",
    "    task: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "class Genie(BaseModel):\n",
    "    space_id: str\n",
    "    name: str\n",
    "    task: str = GENIE\n",
    "    description: str\n",
    "\n",
    "\n",
    "class InCodeSubAgent(BaseModel):\n",
    "    tools: list[str]\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "def stringify_content(state):\n",
    "    msgs = state[\"messages\"]\n",
    "    if isinstance(msgs[-1].content, list):\n",
    "        msgs[-1].content = json.dumps(msgs[-1].content, indent=4)\n",
    "    return {\"messages\": msgs}\n",
    "\n",
    "\n",
    "########################################\n",
    "# Build Domain Tools (Genie + UC Functions)\n",
    "########################################\n",
    "\n",
    "def build_domain_tools(\n",
    "    externally_served_agents: list[ServedSubAgent | Genie],\n",
    "    in_code_agents: list[InCodeSubAgent],\n",
    ") -> list:\n",
    "    \"\"\"Build the domain-specific tools (Genie, UC functions, served agents).\n",
    "\n",
    "    These are the tools the agent uses for actual work. Planning tools\n",
    "    (write_todos, read_todos) and filesystem tools (ls, read_file, write_file,\n",
    "    edit_file, glob, grep) are provided by middleware — not assembled here.\n",
    "\n",
    "    Returns:\n",
    "        List of LangChain tool objects\n",
    "    \"\"\"\n",
    "    domain_tools = []\n",
    "\n",
    "    # UC function tools\n",
    "    for agent_config in in_code_agents:\n",
    "        uc_toolkit = UCFunctionToolkit(function_names=agent_config.tools)\n",
    "        domain_tools.extend(uc_toolkit.tools)\n",
    "\n",
    "    # Genie and served endpoint tools\n",
    "    for agent_config in externally_served_agents:\n",
    "        if isinstance(agent_config, Genie):\n",
    "            genie_agent = GenieAgent(\n",
    "                genie_space_id=agent_config.space_id,\n",
    "                genie_agent_name=agent_config.name,\n",
    "                description=agent_config.description,\n",
    "            )\n",
    "\n",
    "            @tool\n",
    "            def genie_query_tool(question: str, _agent=genie_agent) -> str:\n",
    "                \"\"\"Query the Genie Space for data about Databricks consumption.\n",
    "\n",
    "                Use this tool to get data from tables including:\n",
    "                - Customer accounts and consumption metrics\n",
    "                - DBU usage and costs\n",
    "                - Use case details, timelines, and status\n",
    "                - Databricks SKU information\n",
    "\n",
    "                Genie can execute SQL queries based on natural language questions.\n",
    "                You can call this tool multiple times with different questions.\n",
    "\n",
    "                IMPORTANT: To prevent context overflow, use aggregations and limits:\n",
    "                - Request aggregated/summarized data when possible (GROUP BY, SUM, AVG)\n",
    "                - Add \"LIMIT 50\" or similar to avoid retrieving thousands of rows\n",
    "\n",
    "                Args:\n",
    "                    question: Natural language question about the data (include LIMIT clauses)\n",
    "\n",
    "                Returns:\n",
    "                    Data results and insights from Genie\n",
    "                \"\"\"\n",
    "                result = _agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": question}]})\n",
    "                return result[\"messages\"][-1].content\n",
    "\n",
    "            genie_query_tool.name = agent_config.name.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "            domain_tools.append(genie_query_tool)\n",
    "\n",
    "        else:\n",
    "            model = ChatDatabricks(\n",
    "                endpoint=agent_config.endpoint_name,\n",
    "                use_responses_api=\"responses\" in agent_config.task\n",
    "            )\n",
    "            model._stream = lambda x: model._stream(**x, stream=False)\n",
    "            served_agent = create_react_agent(\n",
    "                model,\n",
    "                tools=[],\n",
    "                name=agent_config.name,\n",
    "                post_model_hook=stringify_content,\n",
    "            )\n",
    "\n",
    "            @tool\n",
    "            def served_agent_tool(task: str, _agent=served_agent, _name=agent_config.name) -> str:\n",
    "                f\"\"\"Delegate task to {_name}.\n",
    "\n",
    "                {agent_config.description}\n",
    "\n",
    "                Args:\n",
    "                    task: The task or question to send to this agent\n",
    "\n",
    "                Returns:\n",
    "                    Response from the agent\n",
    "                \"\"\"\n",
    "                result = _agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": task}]})\n",
    "                return result[\"messages\"][-1].content\n",
    "\n",
    "            served_agent_tool.name = agent_config.name.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "            domain_tools.append(served_agent_tool)\n",
    "\n",
    "    return domain_tools\n",
    "\n",
    "\n",
    "########################################\n",
    "# System Prompt (domain-only, no tool instructions)\n",
    "########################################\n",
    "\n",
    "def build_system_prompt() -> str:\n",
    "    \"\"\"Build the system prompt with domain-specific instructions only.\n",
    "\n",
    "    Tool usage instructions for planning (write_todos, read_todos) and\n",
    "    filesystem (ls, read_file, write_file, etc.) are injected by their\n",
    "    respective middleware — they should NOT be duplicated here.\n",
    "    \"\"\"\n",
    "    current_date = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "    return f\"\"\"You are an AI assistant for analyzing Databricks consumption at various customers and creating reports.\n",
    "\n",
    "CURRENT DATE: {current_date}\n",
    "NOTE: Databricks fiscal year starts February 1st. Use fiscal quarters/years for all time-based queries (FY Q1=Feb-Apr, Q2=May-Jul, Q3=Aug-Oct, Q4=Nov-Jan) where needed.\n",
    "\n",
    "KEY ANALYSIS GUIDELINES:\n",
    "- Focus on DOLLARS as the primary metric (only analyze DBUs if explicitly requested)\n",
    "- Use COMPLETED time periods by default (completed months, quarters, weeks) - exclude current/ongoing periods unless specifically asked to include them\n",
    "- When working with Account Executives, call get_accounts_by_account_executive FIRST to identify which accounts you need to analyze\n",
    "\n",
    "PLANNING AND EXECUTION:\n",
    "For COMPLEX tasks (reports, multi-step analysis, questions requiring multiple data sources):\n",
    "1. Use write_todos at the start to create a comprehensive plan with ALL anticipated steps\n",
    "2. If querying by AE name, include a step to call get_accounts_by_account_executive to identify accounts\n",
    "3. Execute each step by calling the appropriate tools\n",
    "4. After completing each step, call write_todos to update the status of completed items\n",
    "5. Use read_todos periodically to stay focused and see what's left\n",
    "6. Synthesize comprehensive answer when all steps are complete\n",
    "\n",
    "For SIMPLE tasks (single data query, straightforward question):\n",
    "1. Call the appropriate tool directly\n",
    "2. Return the result\n",
    "\n",
    "QUERY OPTIMIZATION:\n",
    "- When querying Genie, use aggregations (SUM, AVG, COUNT, GROUP BY) instead of raw data when possible\n",
    "- Add LIMIT clauses (e.g., \"LIMIT 50\") to Genie queries to avoid retrieving thousands of rows\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "- You can call any tool multiple times with different inputs\n",
    "- Break down complex questions into specific, answerable sub-questions\n",
    "- For data queries, use the Genie tool which can execute SQL\n",
    "- Always synthesize results into a clear, comprehensive answer\n",
    "- Track your progress with TODOs to avoid losing focus\n",
    "- DO NOT continuously revise your TODO plan - create it once, then execute\n",
    "- When you have answered the question, STOP - do not look for additional work\n",
    "- When using a UC tool, return the complete table output as returned by the tool itself.\"\"\"\n",
    "\n",
    "\n",
    "########################################\n",
    "# Create Agent with Middleware\n",
    "########################################\n",
    "\n",
    "def create_langgraph_supervisor(\n",
    "    llm: BaseChatModel,\n",
    "    externally_served_agents: list[ServedSubAgent | Genie] = [],\n",
    "    in_code_agents: list[InCodeSubAgent] = [],\n",
    ") -> CompiledStateGraph:\n",
    "    \"\"\"Create a planning supervisor agent using langchain create_agent with middleware.\n",
    "\n",
    "    Middleware provides (automatically, no prompt engineering needed):\n",
    "    - TodoListMiddleware: write_todos, read_todos tools + planning system prompt\n",
    "    - FilesystemMiddleware: ls, read_file, write_file, edit_file, glob, grep tools\n",
    "      + auto-eviction of large tool results to /large_tool_results/\n",
    "    - SummarizationMiddleware: token-aware context management, summarizes\n",
    "      conversation when approaching context budget\n",
    "    - PatchToolCallsMiddleware: handles dangling tool calls in message history\n",
    "\n",
    "    Args:\n",
    "        llm: Foundation model (ChatDatabricks instance)\n",
    "        externally_served_agents: Genie spaces and served endpoints\n",
    "        in_code_agents: UC function agents\n",
    "\n",
    "    Returns:\n",
    "        Compiled agent graph\n",
    "    \"\"\"\n",
    "    domain_tools = build_domain_tools(externally_served_agents, in_code_agents)\n",
    "    system_prompt = build_system_prompt()\n",
    "\n",
    "    middleware = [\n",
    "        TodoListMiddleware(),\n",
    "        FilesystemMiddleware(\n",
    "            # Auto-evict tool results larger than ~60K chars (15K tokens * 4 chars/token)\n",
    "            # to /large_tool_results/ in the virtual filesystem.\n",
    "            # This prevents Genie results from consuming the 128K context window.\n",
    "            tool_token_limit_before_evict=15000,\n",
    "        ),\n",
    "        SummarizationMiddleware(\n",
    "            model=llm,\n",
    "            # Summarize conversation when it exceeds ~90K tokens (~70% of 128K).\n",
    "            # Keeps 6 most recent messages after summarization.\n",
    "            max_tokens_before_summary=90000,\n",
    "            messages_to_keep=6,\n",
    "        ),\n",
    "        PatchToolCallsMiddleware(),\n",
    "    ]\n",
    "\n",
    "    agent = create_agent(\n",
    "        model=llm,\n",
    "        system_prompt=system_prompt,\n",
    "        tools=domain_tools,\n",
    "        middleware=middleware,\n",
    "    )\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "def create_supervisor_with_formatter(\n",
    "    llm: BaseChatModel,\n",
    "    externally_served_agents: list[ServedSubAgent | Genie] = [],\n",
    "    in_code_agents: list[InCodeSubAgent] = [],\n",
    ") -> CompiledStateGraph:\n",
    "    \"\"\"Create supervisor agent with post-processing formatter node.\n",
    "\n",
    "    Wraps the base supervisor with a formatter that:\n",
    "    1. Removes file operation references from responses\n",
    "    2. Applies consistent formatting templates\n",
    "    \"\"\"\n",
    "    supervisor = create_langgraph_supervisor(llm, externally_served_agents, in_code_agents)\n",
    "\n",
    "    def format_final_response(state: dict) -> dict:\n",
    "        \"\"\"Reformat final AI message to remove file references and apply templates.\"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "        last_ai_message = None\n",
    "        for msg in reversed(messages):\n",
    "            if msg.type == \"ai\":\n",
    "                last_ai_message = msg\n",
    "                break\n",
    "\n",
    "        if last_ai_message and last_ai_message.content:\n",
    "            content = last_ai_message.content\n",
    "            content = remove_file_references(content)\n",
    "            content = apply_format_template(content, state)\n",
    "            last_ai_message.content = content\n",
    "\n",
    "        return {\"messages\": messages}\n",
    "\n",
    "    # Use FilesystemState so the outer graph propagates the 'files' channel\n",
    "    # from the supervisor subgraph (needed for custom_outputs in predict()).\n",
    "    workflow = StateGraph(FilesystemState)\n",
    "    workflow.add_node(\"supervisor\", supervisor)\n",
    "    workflow.add_node(\"formatter\", format_final_response)\n",
    "\n",
    "    workflow.set_entry_point(\"supervisor\")\n",
    "    workflow.add_edge(\"supervisor\", \"formatter\")\n",
    "    workflow.add_edge(\"formatter\", END)\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "##########################################\n",
    "# Wrap as MLflow ResponsesAgent\n",
    "##########################################\n",
    "\n",
    "class LazyLangGraphResponsesAgent(ResponsesAgent):\n",
    "    \"\"\"MLflow ResponsesAgent wrapper with lazy initialization.\n",
    "\n",
    "    Message sanitization, trimming, and truncation are handled by middleware:\n",
    "    - PatchToolCallsMiddleware: fixes dangling tool calls\n",
    "    - SummarizationMiddleware: token-aware context management\n",
    "    - FilesystemMiddleware: auto-evicts large tool results\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._agent = None\n",
    "        self._final_state = None\n",
    "\n",
    "    @property\n",
    "    def agent(self):\n",
    "        if self._agent is None:\n",
    "            self._agent = get_supervisor()\n",
    "        return self._agent\n",
    "\n",
    "    def _langchain_to_responses(self, message: BaseMessage) -> list[dict[str, Any]]:\n",
    "        \"\"\"Convert LangChain message to Responses API output items.\"\"\"\n",
    "        message = message.model_dump()\n",
    "        role = message[\"type\"]\n",
    "        output = []\n",
    "        if role == \"ai\":\n",
    "            if message.get(\"content\"):\n",
    "                output.append(\n",
    "                    self.create_text_output_item(\n",
    "                        text=message[\"content\"],\n",
    "                        id=message.get(\"id\") or str(uuid4()),\n",
    "                    )\n",
    "                )\n",
    "            if tool_calls := message.get(\"tool_calls\"):\n",
    "                output.extend(\n",
    "                    [\n",
    "                        self.create_function_call_item(\n",
    "                            id=message.get(\"id\") or str(uuid4()),\n",
    "                            call_id=tool_call[\"id\"],\n",
    "                            name=tool_call[\"name\"],\n",
    "                            arguments=json.dumps(tool_call[\"args\"]),\n",
    "                        )\n",
    "                        for tool_call in tool_calls\n",
    "                    ]\n",
    "                )\n",
    "        elif role == \"tool\":\n",
    "            output.append(\n",
    "                self.create_function_call_output_item(\n",
    "                    call_id=message[\"tool_call_id\"],\n",
    "                    output=message[\"content\"],\n",
    "                )\n",
    "            )\n",
    "        return output\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\"\n",
    "        ]\n",
    "\n",
    "        files = {}\n",
    "        if self._final_state:\n",
    "            files = self._final_state.get(\"files\", {})\n",
    "\n",
    "        return ResponsesAgentResponse(\n",
    "            output=outputs,\n",
    "            custom_outputs={\n",
    "                **(request.custom_inputs or {}),\n",
    "                \"files\": files,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        request: ResponsesAgentRequest,\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        cc_msgs = self.prep_msgs_for_cc_llm([i.model_dump() for i in request.input])\n",
    "\n",
    "        # Middleware handles sanitization, trimming, and truncation:\n",
    "        # - PatchToolCallsMiddleware: fixes dangling tool calls\n",
    "        # - SummarizationMiddleware: token-aware context management\n",
    "        # - FilesystemMiddleware: auto-evicts large tool results\n",
    "\n",
    "        first_name = True\n",
    "        seen_ids = set()\n",
    "\n",
    "        initial_state = {\"messages\": cc_msgs}\n",
    "        config = {\"recursion_limit\": 100}\n",
    "\n",
    "        for event_name, events in self.agent.stream(initial_state, config=config, stream_mode=[\"updates\"]):\n",
    "            if event_name == \"updates\":\n",
    "                if not first_name:\n",
    "                    node_name = tuple(events.keys())[0]\n",
    "                    if node_name != \"formatter\":\n",
    "                        yield ResponsesAgentStreamEvent(\n",
    "                            type=\"response.output_item.done\",\n",
    "                            item=self.create_text_output_item(\n",
    "                                text=f\"<name>{node_name}</name>\",\n",
    "                                id=str(uuid4()),\n",
    "                            ),\n",
    "                        )\n",
    "                for node_data in events.values():\n",
    "                    self._final_state = node_data\n",
    "\n",
    "                    for msg in node_data[\"messages\"]:\n",
    "                        if msg.id not in seen_ids:\n",
    "                            seen_ids.add(msg.id)\n",
    "                            for item in self._langchain_to_responses(msg):\n",
    "                                yield ResponsesAgentStreamEvent(\n",
    "                                    type=\"response.output_item.done\", item=item\n",
    "                                )\n",
    "            first_name = False\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Configure the Foundation Model and Serving Sub-Agents\n",
    "#######################################################\n",
    "\n",
    "LLM_ENDPOINT_NAME = \"databricks-gpt-oss-120b\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "EXTERNALLY_SERVED_AGENTS = [\n",
    "    Genie(\n",
    "        space_id=\"01f0fd193cf412f7a40f97d24851c0d1\",\n",
    "        name=\"logfood-genie\",\n",
    "        description=\"This Genie agent can answer questions based on a database containing tables related to Databricks consumption at different customers, including accounts, dollars, dbus, the Databricks SKU along with Use Case details such as target live dates, use case descriptions and updates. Use Genie to fetch and analyze data from these tables by specifying the relevant columns and filters. Genie can execute SQL queries to provide precise data insights based on your questions.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "IN_CODE_AGENTS = [\n",
    "    InCodeSubAgent(\n",
    "        tools=[\"ankit_yadav.demo.get_accounts_by_account_executive\"],\n",
    "        name=\"account lookup\",\n",
    "        description=\"Returns selected account details managed by a specific Account Executive. Use this tool FIRST when working with AE names to identify which accounts you need to analyze before querying consumption data.\",\n",
    "    ),\n",
    "    InCodeSubAgent(\n",
    "        tools=[\"ankit_yadav.demo.get_account_summaries\"],\n",
    "        name=\"account summary\",\n",
    "        description=\"Generates AI-powered account-level summaries for all accounts managed by a specific Account Executive. Analyzes use case patterns, pipeline health, opportunities, and risks across all use cases per account. Use for comprehensive account overviews and strategic insights.\",\n",
    "    ),\n",
    "    InCodeSubAgent(\n",
    "        tools=[\"ankit_yadav.demo.get_live_date_follow_up_messages\"],\n",
    "        name=\"follow-up messages\",\n",
    "        description=\"Generates AI-powered follow-up messages for use cases targeting go-live in current or next month. Pass specific AE name, multiple names separated by comma, or NULL/'ALL' for all AEs. Creates concise Slack/Teams-ready messages for AE and SA based on next steps and use case details. Returns account, use case info, target live date, days until live, current stage, monthly dollars, and tailored follow-up message.\",\n",
    "    )\n",
    "]\n",
    "\n",
    "#################################################\n",
    "# Build TOOLS list for resource registration\n",
    "#################################################\n",
    "\n",
    "# UC function tools (needed by resource setup cell for DatabricksFunction registration)\n",
    "TOOLS = []\n",
    "for _agent_cfg in IN_CODE_AGENTS:\n",
    "    _uc_toolkit = UCFunctionToolkit(function_names=_agent_cfg.tools)\n",
    "    TOOLS.extend(_uc_toolkit.tools)\n",
    "\n",
    "#################################################\n",
    "# Create supervisor and set up MLflow for tracing\n",
    "#################################################\n",
    "\n",
    "_supervisor = None\n",
    "\n",
    "def get_supervisor():\n",
    "    \"\"\"Lazily create supervisor on first use to avoid model loading timeout.\"\"\"\n",
    "    global _supervisor\n",
    "    if _supervisor is None:\n",
    "        _supervisor = create_supervisor_with_formatter(llm, EXTERNALLY_SERVED_AGENTS, IN_CODE_AGENTS)\n",
    "    return _supervisor\n",
    "\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LazyLangGraphResponsesAgent()\n",
    "mlflow.models.set_model(AGENT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0103f4c-4a1f-40ca-9f3d-28bcd1803ec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output. Since this notebook called `mlflow.langchain.autolog()` you can view the trace for each step the agent takes.\n",
    "\n",
    "**Important:** LangGraph internally uses exceptions (something like `Command` or `ParentCommand`) to switch between nodes. These particular exceptions may appear in your MLflow traces as Events, but this behavior is expected and should not be a cause for concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11079f06-9837-4208-af79-2d910058cf2d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restart Python Environment to Apply Library Changes"
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1ed7c81-8208-42d0-81a9-e8409c4088b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.7\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2964b0a-4a73-41ee-8b41-0bd8ff8b8ac9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Agent Input Setup and Predict Call with User Query"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/lib/dbruntime/autoreload/discoverability/autoreload_discoverability_hook.py:72: UserWarning: Ignoring the default notebook Spark session and creating a new Spark Connect session. To use the default notebook Spark session, use DatabricksSession.builder.getOrCreate() with no additional parameters.\n  return orig_warn(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResponsesAgentResponse(tool_choice=None, truncation=None, id=None, created_at=None, error=None, incomplete_details=None, instructions=None, metadata=None, model=None, object='response', output=[OutputItem(type='message', id='lc_run--019c0a23-6705-71f1-bb01-45ab0500f69f-0', content=[{'text': 'Here are the tools I can use to help you:\\n\\n**Data & Account‑related tools**\\n- **ankit_yadav__demo__get_accounts_by_account_executive** – Retrieve a list of accounts managed by a specific Account Executive.  \\n- **ankit_yadav__demo__get_account_summaries** – Generate AI‑powered summaries for all accounts of a given AE (use‑case patterns, pipeline health, opportunities, risks, etc.).  \\n- **ankit_yadav__demo__get_live_date_follow_up_messages** – Create concise follow‑up messages for use cases that are slated to go live this month or next.  \\n- **logfood_genie** – Query the Genie data warehouse for Databricks consumption, costs, DBU usage, SKU info, timelines, and other analytics via natural‑language‑to‑SQL conversion.\\n\\n**File‑system tools**\\n- **ls** – List files in a directory.  \\n- **read_file** – Read the contents of a file (supports pagination).  \\n- **write_file** – Create a new file with specified content.  \\n- **edit_file** – Perform exact string replacements in an existing file.  \\n- **glob** – Find files matching a glob pattern.  \\n- **grep** – Search for literal text across files.\\n\\n**Task‑management tool**\\n- **write_todos** – Create and manage a structured to‑do list for multi‑step projects (mark tasks as pending, in_progress, or completed).\\n\\nI can combine these tools as needed to gather data, analyze it, and produce reports or answers for you. Let me know what you’d like to do!', 'type': 'output_text'}], role='assistant')], parallel_tool_calls=None, temperature=None, tools=None, top_p=None, max_output_tokens=None, previous_response_id=None, reasoning=None, status=None, text=None, usage=None, user=None, custom_outputs={'files': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "{\"trace_id\": \"tr-746b7de531add45aa16b06498288c33d\", \"sql_warehouse_id\": null}",
      "text/plain": [
       "Trace(trace_id=tr-746b7de531add45aa16b06498288c33d)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agent_dev import AGENT\n",
    "\n",
    "# TODO: Replace this placeholder `input_example` with a domain-specific prompt for your agent.\n",
    "input_example = {\"input\": [{\"role\": \"user\", \"content\": \"What tools are available to you\"}]}\n",
    "\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2a9542f-49b3-4f8e-941e-70dea6df082a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from agent_dev import AGENT\n",
    "\n",
    "# # TODO: Replace this placeholder `input_example` with a domain-specific prompt for your agent.\n",
    "# input_example = {\"input\": [{\"role\": \"user\", \"content\": \"What is the trend for JOsh Hermans accounts over the last three quarters? Give me a quarter over quarter % change for his accounts\"}]}\n",
    "\n",
    "# AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af022e19-a090-41fa-9c9a-d64c43ca334f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stream Agent Predictions with Model Output Display"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'response.output_item.done', 'item': {'id': 'lc_run--019c0a23-a324-7a93-9446-d30446a200f0-0', 'content': [{'text': 'Here’s a quick rundown of the tools I can use while working with you:\\n\\n### Project‑management / planning\\n- **`write_todos`** – Create, update, and track a structured todo list for multi‑step tasks.\\n\\n### Filesystem utilities\\n- **`ls`** – List the contents of a directory.  \\n- **`read_file`** – Read the contents of a file (with optional pagination).  \\n- **`write_file`** – Create a new file with supplied content.  \\n- **`edit_file`** – Perform exact‑string replacements in an existing file.  \\n- **`glob`** – Find files that match a glob pattern (e.g., `**/*.py`).  \\n- **`grep`** – Search for literal text across files, returning matching file names or line content.\\n\\n### Databricks‑specific data APIs\\n- **`ankit_yadav__demo__get_accounts_by_account_executive`** – Retrieve a list of customer accounts managed by a given Account Executive.  \\n- **`ankit_yadav__demo__get_account_summaries`** – Generate AI‑powered summary reports for all accounts under a specific AE (use‑case patterns, pipeline health, opportunities, risks, etc.).  \\n- **`ankit_yadav__demo__get_live_date_follow_up_messages`** – Create concise follow‑up Slack/Teams messages for use‑cases that are slated to go live this month or next.  \\n\\n### Genie data‑query engine\\n- **`logfood_genie`** – Run natural‑language‑to‑SQL queries against Databricks consumption data (accounts, DBU usage, costs, SKUs, timelines, statuses, etc.). The tool returns the query results directly.\\n\\nThese tools let me explore files, manage tasks, retrieve account information, generate summaries or follow‑up messages, and query consumption data to produce the analyses and reports you need. Let me know which one(s) you’d like me to use!', 'type': 'output_text'}], 'role': 'assistant', 'type': 'message'}}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "{\"trace_id\": \"tr-974e3a20f3ab439d75c25e90fb1458d0\", \"sql_warehouse_id\": null}",
      "text/plain": [
       "Trace(trace_id=tr-974e3a20f3ab439d75c25e90fb1458d0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for event in AGENT.predict_stream(input_example):\n",
    "  print(event.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "299790ba-cd17-4f11-babc-1bc6d3c18cc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code).\n",
    "\n",
    "### Enable automatic authentication for Databricks resources\n",
    "For the most common Databricks resource types, Databricks supports and recommends declaring resource dependencies for the agent upfront during logging. This enables automatic authentication passthrough when you deploy the agent. With automatic authentication passthrough, Databricks automatically provisions, rotates, and manages short-lived credentials to securely access these resource dependencies from within the agent endpoint.\n",
    "\n",
    "To enable automatic authentication, specify the dependent Databricks resources when calling `mlflow.pyfunc.log_model().`\n",
    "  - **TODO**: If your Unity Catalog tool queries a [vector search index](docs link) or leverages [external functions](docs link), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See docs ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-authentication#supported-resources-for-automatic-authentication-passthrough) | [Azure](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-authentication#supported-resources-for-automatic-authentication-passthrough)).\n",
    "\n",
    "  - **TODO**: Add the SQL Warehouse or tables powering your Genie space to enable passthrough authentication. ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-authentication#supported-resources-for-automatic-authentication-passthrough) | [Azure](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-authentication#supported-resources-for-automatic-authentication-passthrough)). If your genie space uses \"embedded credentials\" then you do not have to add this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a7fdf0-d9a1-4d5b-ab3e-2044da70eaa1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Up Databricks Resources and Log Agent Model"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 View Logged Model at: https://fe-sandbox-serverless-9thezy.cloud.databricks.com/ml/experiments/1642964254361159/models/m-e1dd47eba9cf42cda4db417556abc942?o=7474651123329331\n/databricks/python/lib/python3.12/site-packages/databricks/connect/session.py:477: UserWarning: Ignoring the default notebook Spark session and creating a new Spark Connect session. To use the default notebook Spark session, use DatabricksSession.builder.getOrCreate() with no additional parameters.\n  warnings.warn(new_notebook_session_msg)\n2026/01/29 14:24:12 INFO mlflow.pyfunc: Predicting on input example to validate output\n2026/01/29 14:24:12 WARNING mlflow.tracing.fluent: Failed to start span predict_stream: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n2026/01/29 14:24:13 WARNING mlflow.tracing.fluent: Failed to start span LangGraph: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n/databricks/python/lib/python3.12/site-packages/databricks/connect/session.py:477: UserWarning: Ignoring the default notebook Spark session and creating a new Spark Connect session. To use the default notebook Spark session, use DatabricksSession.builder.getOrCreate() with no additional parameters.\n  warnings.warn(new_notebook_session_msg)\n2026/01/29 14:24:16 WARNING mlflow.tracing.fluent: Failed to start span predict_stream: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n2026/01/29 14:24:16 WARNING mlflow.tracing.fluent: Failed to start span LangGraph: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n"
     ]
    }
   ],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent_dev import EXTERNALLY_SERVED_AGENTS, LLM_ENDPOINT_NAME, TOOLS, Genie\n",
    "from databricks_langchain import UnityCatalogTool, VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksGenieSpace,\n",
    "    DatabricksServingEndpoint,\n",
    "    DatabricksSQLWarehouse,\n",
    "    DatabricksTable\n",
    ")\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "# TODO: Manually include underlying resources if needed. See the TODO in the markdown above for more information.\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "# TODO: Add SQL Warehouses and delta tables powering the Genie Space\n",
    "resources.append(DatabricksSQLWarehouse(warehouse_id=\"9f759a35683b2137\"))\n",
    "resources.append(DatabricksTable(table_name=\"ankit_yadav.demo.dim_accounts\"))\n",
    "resources.append(DatabricksTable(table_name=\"ankit_yadav.demo.fact_consumption_weekly\"))\n",
    "resources.append(DatabricksTable(table_name=\"ankit_yadav.demo.fact_consumption_daily\"))\n",
    "resources.append(DatabricksTable(table_name=\"ankit_yadav.demo.fact_consumption_monthly\"))\n",
    "resources.append(DatabricksTable(table_name=\"ankit_yadav.demo.dim_use_cases\"))\n",
    "\n",
    "\n",
    "\n",
    "# Add tools from Unity Catalog\n",
    "for tool in TOOLS:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "# Add serving endpoints and Genie Spaces\n",
    "for agent in EXTERNALLY_SERVED_AGENTS:\n",
    "    if isinstance(agent, Genie):\n",
    "        resources.append(DatabricksGenieSpace(genie_space_id=agent.space_id))\n",
    "    else:\n",
    "        resources.append(DatabricksServingEndpoint(endpoint_name=agent.endpoint_name))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent_dev\",\n",
    "        python_model=\"agent_dev.py\",\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "    f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "    f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "    f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "    f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "    f\"langgraph-supervisor=={get_distribution('langgraph-supervisor').version}\",\n",
    "    f\"langchain=={get_distribution('langchain').version}\",\n",
    "    f\"deepagents=={get_distribution('deepagents').version}\",\n",
    "],\n",
    "\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "136c836c-8344-4817-80cd-cfbc3f2df3d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pre-deployment agent validation\n",
    "Before registering and deploying the agent, perform pre-deployment checks using the [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API. See Databricks documentation ([AWS](https://docs.databricks.com/en/machine-learning/model-serving/model-serving-debug.html#validate-inputs) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/model-serving-debug#before-model-deployment-validation-checks))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aba434a-d6b5-4169-90b0-39b6557a5c6a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Agent Model Prediction Call Using MLflow URI"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d868ffe289941489eb4f08e83f39e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff81f17356a342249995850a05e4e61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/29 14:24:25 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909bfd0f7e524f8dbc3d39cfe7695a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0affa14b9e1e43ef900956b4d5ce96a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/29 14:24:28 INFO mlflow.utils.virtualenv: Creating a new environment in /tmp/virtualenv_envs/mlflow-04a354c89f2e7c0da1c602cd033dbef842728f7f with python version 3.12.3 using uv\nUsing CPython 3.12.3 interpreter at: \u001B[36m/usr/bin/python3.12\u001B[39m\nCreating virtual environment at: \u001B[36m/tmp/virtualenv_envs/mlflow-04a354c89f2e7c0da1c602cd033dbef842728f7f\u001B[39m\nActivate with: \u001B[32msource /tmp/virtualenv_envs/mlflow-04a354c89f2e7c0da1c602cd033dbef842728f7f/bin/activate\u001B[39m\n2026/01/29 14:24:29 INFO mlflow.utils.virtualenv: Installing dependencies\n\u001B[2mUsing Python 3.12.3 environment at: /tmp/virtualenv_envs/mlflow-04a354c89f2e7c0da1c602cd033dbef842728f7f\u001B[0m\n\u001B[2mResolved \u001B[1m3 packages\u001B[0m \u001B[2min 37ms\u001B[0m\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pip \u001B[2m(1.8MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m setuptools \u001B[2m(1.2MiB)\u001B[0m\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pip\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m setuptools\n\u001B[2mPrepared \u001B[1m3 packages\u001B[0m \u001B[2min 169ms\u001B[0m\u001B[0m\n\u001B[2mInstalled \u001B[1m3 packages\u001B[0m \u001B[2min 21ms\u001B[0m\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpip\u001B[0m\u001B[2m==25.0.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msetuptools\u001B[0m\u001B[2m==75.8.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwheel\u001B[0m\u001B[2m==0.45.1\u001B[0m\n\u001B[2mUsing Python 3.12.3 environment at: /tmp/virtualenv_envs/mlflow-04a354c89f2e7c0da1c602cd033dbef842728f7f\u001B[0m\n\u001B[2mResolved \u001B[1m161 packages\u001B[0m \u001B[2min 1.22s\u001B[0m\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m databricks-connect \u001B[2m(2.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m sqlalchemy \u001B[2m(3.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-tracing \u001B[2m(1.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m tiktoken \u001B[2m(1.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m langchain-community \u001B[2m(2.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m openai \u001B[2m(1.0MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pillow \u001B[2m(6.7MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m zstandard \u001B[2m(5.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m grpcio \u001B[2m(6.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m numpy \u001B[2m(17.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pandas \u001B[2m(11.8MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m fonttools \u001B[2m(4.7MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-skinny \u001B[2m(2.7MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m cryptography \u001B[2m(4.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m aiohttp \u001B[2m(1.7MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pydantic-core \u001B[2m(2.0MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m scipy \u001B[2m(33.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pyarrow \u001B[2m(45.5MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m kiwisolver \u001B[2m(1.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m matplotlib \u001B[2m(8.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m scikit-learn \u001B[2m(8.5MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow \u001B[2m(9.2MiB)\u001B[0m\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m tiktoken\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m kiwisolver\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m aiohttp\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pydantic-core\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m mlflow-tracing\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m databricks-connect\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m sqlalchemy\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m cryptography\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m fonttools\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m zstandard\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m openai\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m grpcio\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pillow\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m mlflow-skinny\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m langchain-community\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m matplotlib\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m numpy\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m scikit-learn\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m mlflow\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m scipy\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pyarrow\n \u001B[36m\u001B[1mDownloaded\u001B[0m\u001B[39m pandas\n\u001B[2mPrepared \u001B[1m160 packages\u001B[0m \u001B[2min 5.46s\u001B[0m\u001B[0m\n\u001B[2mInstalled \u001B[1m160 packages\u001B[0m \u001B[2min 513ms\u001B[0m\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohappyeyeballs\u001B[0m\u001B[2m==2.6.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohttp\u001B[0m\u001B[2m==3.13.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohttp-retry\u001B[0m\u001B[2m==2.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiosignal\u001B[0m\u001B[2m==1.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1malembic\u001B[0m\u001B[2m==1.18.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mannotated-doc\u001B[0m\u001B[2m==0.0.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mannotated-types\u001B[0m\u001B[2m==0.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1manthropic\u001B[0m\u001B[2m==0.76.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1manyio\u001B[0m\u001B[2m==4.12.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mattrs\u001B[0m\u001B[2m==25.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mblinker\u001B[0m\u001B[2m==1.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mbracex\u001B[0m\u001B[2m==2.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcachetools\u001B[0m\u001B[2m==6.2.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcertifi\u001B[0m\u001B[2m==2026.1.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcffi\u001B[0m\u001B[2m==2.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcharset-normalizer\u001B[0m\u001B[2m==3.4.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mclick\u001B[0m\u001B[2m==8.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcloudpickle\u001B[0m\u001B[2m==3.1.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcontourpy\u001B[0m\u001B[2m==1.3.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcryptography\u001B[0m\u001B[2m==46.0.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcycler\u001B[0m\u001B[2m==0.12.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-ai-bridge\u001B[0m\u001B[2m==0.13.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-connect\u001B[0m\u001B[2m==16.4.11\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-langchain\u001B[0m\u001B[2m==0.14.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-mcp\u001B[0m\u001B[2m==0.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-sdk\u001B[0m\u001B[2m==0.82.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-vectorsearch\u001B[0m\u001B[2m==0.64\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdataclasses-json\u001B[0m\u001B[2m==0.6.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdeepagents\u001B[0m\u001B[2m==0.3.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdeprecation\u001B[0m\u001B[2m==2.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdistro\u001B[0m\u001B[2m==1.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdocker\u001B[0m\u001B[2m==7.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdocstring-parser\u001B[0m\u001B[2m==0.17.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfastapi\u001B[0m\u001B[2m==0.128.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfiletype\u001B[0m\u001B[2m==1.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mflask\u001B[0m\u001B[2m==3.1.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mflask-cors\u001B[0m\u001B[2m==6.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfonttools\u001B[0m\u001B[2m==4.61.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfrozenlist\u001B[0m\u001B[2m==1.8.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgitdb\u001B[0m\u001B[2m==4.0.12\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgitpython\u001B[0m\u001B[2m==3.1.46\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgoogle-auth\u001B[0m\u001B[2m==2.48.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgoogle-genai\u001B[0m\u001B[2m==1.60.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgoogleapis-common-protos\u001B[0m\u001B[2m==1.72.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphene\u001B[0m\u001B[2m==3.4.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphql-core\u001B[0m\u001B[2m==3.2.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphql-relay\u001B[0m\u001B[2m==3.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgreenlet\u001B[0m\u001B[2m==3.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgrpcio\u001B[0m\u001B[2m==1.76.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgrpcio-status\u001B[0m\u001B[2m==1.76.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgunicorn\u001B[0m\u001B[2m==23.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mh11\u001B[0m\u001B[2m==0.16.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpcore\u001B[0m\u001B[2m==1.0.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpx\u001B[0m\u001B[2m==0.28.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpx-sse\u001B[0m\u001B[2m==0.4.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhuey\u001B[0m\u001B[2m==2.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1midna\u001B[0m\u001B[2m==3.11\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mimportlib-metadata\u001B[0m\u001B[2m==8.7.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mitsdangerous\u001B[0m\u001B[2m==2.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjinja2\u001B[0m\u001B[2m==3.1.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjiter\u001B[0m\u001B[2m==0.12.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjoblib\u001B[0m\u001B[2m==1.5.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonpatch\u001B[0m\u001B[2m==1.33\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonpointer\u001B[0m\u001B[2m==3.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonschema\u001B[0m\u001B[2m==4.26.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonschema-specifications\u001B[0m\u001B[2m==2025.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mkiwisolver\u001B[0m\u001B[2m==1.4.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain\u001B[0m\u001B[2m==1.2.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-anthropic\u001B[0m\u001B[2m==1.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-classic\u001B[0m\u001B[2m==1.0.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-community\u001B[0m\u001B[2m==0.4.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-core\u001B[0m\u001B[2m==1.2.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-google-genai\u001B[0m\u001B[2m==4.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-mcp-adapters\u001B[0m\u001B[2m==0.2.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-text-splitters\u001B[0m\u001B[2m==1.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph\u001B[0m\u001B[2m==1.0.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-checkpoint\u001B[0m\u001B[2m==4.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-prebuilt\u001B[0m\u001B[2m==1.0.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-sdk\u001B[0m\u001B[2m==0.3.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-supervisor\u001B[0m\u001B[2m==0.0.31\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangsmith\u001B[0m\u001B[2m==0.6.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmako\u001B[0m\u001B[2m==1.3.10\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmarkupsafe\u001B[0m\u001B[2m==3.0.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmarshmallow\u001B[0m\u001B[2m==3.26.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmatplotlib\u001B[0m\u001B[2m==3.10.8\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmcp\u001B[0m\u001B[2m==1.26.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow\u001B[0m\u001B[2m==3.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow-skinny\u001B[0m\u001B[2m==3.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow-tracing\u001B[0m\u001B[2m==3.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmultidict\u001B[0m\u001B[2m==6.7.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmypy-extensions\u001B[0m\u001B[2m==1.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnest-asyncio\u001B[0m\u001B[2m==1.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnumpy\u001B[0m\u001B[2m==1.26.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopenai\u001B[0m\u001B[2m==2.16.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-api\u001B[0m\u001B[2m==1.39.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-proto\u001B[0m\u001B[2m==1.39.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-sdk\u001B[0m\u001B[2m==1.39.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-semantic-conventions\u001B[0m\u001B[2m==0.60b1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1morjson\u001B[0m\u001B[2m==3.11.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mormsgpack\u001B[0m\u001B[2m==1.12.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpackaging\u001B[0m\u001B[2m==25.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpandas\u001B[0m\u001B[2m==2.3.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpillow\u001B[0m\u001B[2m==12.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mprettytable\u001B[0m\u001B[2m==3.17.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpropcache\u001B[0m\u001B[2m==0.4.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mprotobuf\u001B[0m\u001B[2m==6.33.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpy4j\u001B[0m\u001B[2m==0.10.9.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyarrow\u001B[0m\u001B[2m==22.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyasn1\u001B[0m\u001B[2m==0.6.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyasn1-modules\u001B[0m\u001B[2m==0.4.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpycparser\u001B[0m\u001B[2m==3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic\u001B[0m\u001B[2m==2.12.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic-core\u001B[0m\u001B[2m==2.41.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic-settings\u001B[0m\u001B[2m==2.12.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyjwt\u001B[0m\u001B[2m==2.10.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyparsing\u001B[0m\u001B[2m==3.3.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-dateutil\u001B[0m\u001B[2m==2.9.0.post0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-dotenv\u001B[0m\u001B[2m==1.2.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-multipart\u001B[0m\u001B[2m==0.0.22\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpytz\u001B[0m\u001B[2m==2025.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyyaml\u001B[0m\u001B[2m==6.0.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mreferencing\u001B[0m\u001B[2m==0.37.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mregex\u001B[0m\u001B[2m==2026.1.15\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrequests\u001B[0m\u001B[2m==2.32.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrequests-toolbelt\u001B[0m\u001B[2m==1.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrpds-py\u001B[0m\u001B[2m==0.30.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrsa\u001B[0m\u001B[2m==4.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mscikit-learn\u001B[0m\u001B[2m==1.8.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mscipy\u001B[0m\u001B[2m==1.17.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msix\u001B[0m\u001B[2m==1.17.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mskops\u001B[0m\u001B[2m==0.13.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msmmap\u001B[0m\u001B[2m==5.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msniffio\u001B[0m\u001B[2m==1.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msqlalchemy\u001B[0m\u001B[2m==2.0.46\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msqlparse\u001B[0m\u001B[2m==0.5.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msse-starlette\u001B[0m\u001B[2m==3.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mstarlette\u001B[0m\u001B[2m==0.50.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtabulate\u001B[0m\u001B[2m==0.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtenacity\u001B[0m\u001B[2m==9.1.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mthreadpoolctl\u001B[0m\u001B[2m==3.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtiktoken\u001B[0m\u001B[2m==0.12.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtqdm\u001B[0m\u001B[2m==4.67.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-extensions\u001B[0m\u001B[2m==4.15.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-inspect\u001B[0m\u001B[2m==0.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-inspection\u001B[0m\u001B[2m==0.4.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtzdata\u001B[0m\u001B[2m==2025.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1munitycatalog-ai\u001B[0m\u001B[2m==0.3.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1munitycatalog-client\u001B[0m\u001B[2m==0.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1munitycatalog-langchain\u001B[0m\u001B[2m==0.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1murllib3\u001B[0m\u001B[2m==2.6.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1muuid-utils\u001B[0m\u001B[2m==0.14.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1muvicorn\u001B[0m\u001B[2m==0.40.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwcmatch\u001B[0m\u001B[2m==10.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwcwidth\u001B[0m\u001B[2m==0.5.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwebsockets\u001B[0m\u001B[2m==15.0.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwerkzeug\u001B[0m\u001B[2m==3.1.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mxxhash\u001B[0m\u001B[2m==3.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1myarl\u001B[0m\u001B[2m==1.22.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mzipp\u001B[0m\u001B[2m==3.23.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mzstandard\u001B[0m\u001B[2m==0.25.0\u001B[0m\n2026/01/29 14:24:36 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-04a354c89f2e7c0da1c602cd033dbef842728f7f/bin/activate && python -c \"\"']'\n2026/01/29 14:24:36 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-04a354c89f2e7c0da1c602cd033dbef842728f7f/bin/activate && python /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae4fd991-bde7-4ebe-aebe-07c4a2565a20/lib/python3.12/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///local_disk0/user_tmp_data/spark-ae4fd991-bde7-4ebe-aebe-07/tmp1sdr8xrz/agent_dev --content-type json --input-path /local_disk0/user_tmp_data/spark-ae4fd991-bde7-4ebe-aebe-07/tmph9bi93sk/input.json']'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\": \"response\", \"output\": [{\"type\": \"message\", \"id\": \"lc_run--019c0a24-8019-7090-abbd-affdea1ff187-0\", \"content\": [{\"text\": \"Here\\u2019s a quick overview of the tools I can use while helping you:\\n\\n| Category | Tool | What it does |\\n|----------|------|--------------|\\n| **Task Management** | `write_todos` | Create, update, and track a structured to\\u2011do list for multi\\u2011step projects. |\\n| **Filesystem** | `ls` | List the contents of a directory. |\\n| | `read_file` | Read a file (with optional pagination). |\\n| | `write_file` | Create a brand\\u2011new file with supplied content. |\\n| | `edit_file` | Perform an exact\\u2011string replacement inside an existing file. |\\n| | `glob` | Find files that match a glob pattern (e.g., `**/*.py`). |\\n| | `grep` | Search for a literal text pattern across files (can return file names, matching lines, or counts). |\\n| **Databricks Consumption Data** | `ankit_yadav__demo__get_accounts_by_account_executive` | Retrieve account details for a given Account Executive. |\\n| | `ankit_yadav__demo__get_account_summaries` | Generate AI\\u2011powered summaries (pipeline health, opportunities, risks, etc.) for all accounts of an AE. |\\n| | `ankit_yadav__demo__get_live_date_follow_up_messages` | Produce concise follow\\u2011up messages for use cases targeting go\\u2011live in the current or next month. |\\n| | `logfood_genie` | Run natural\\u2011language SQL queries against the Genie dataset (customer consumption, DBU usage, costs, use\\u2011case details, etc.). |\\n\\nI can combine these tools as needed\\u2014e.g., query consumption data with **Genie**, pull account lists with the AE\\u2011specific API, or manage a multi\\u2011step analysis with a to\\u2011do list. Just let me know what you\\u2019d like to accomplish!\", \"type\": \"output_text\"}], \"role\": \"assistant\"}], \"custom_outputs\": {\"files\": {}}}"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/29 14:24:57 INFO mlflow.tracing.export.async_export_queue: Flushing the async trace logging queue before program exit. This may take a while...\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent_dev\",\n",
    "    input_data=input_example,\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53dcfac4-0816-4f74-bee6-559740a35235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d10d68c-eaba-432b-a318-333774a999f5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Configure Registry URI and Register UC Model in MLflow"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'ankit_yadav.demo.logfood_agent_dev'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c03bda9c6bb487ea4d2d1f24f7462c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b0dabd0c5f4be0a8e2f95dce063f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '1' of model 'ankit_yadav.demo.logfood_agent_dev': https://fe-sandbox-serverless-9thezy.cloud.databricks.com/explore/data/models/ankit_yadav/demo/logfood_agent_dev/version/1?o=7474651123329331\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"ankit_yadav\"\n",
    "schema = \"demo\"\n",
    "model_name = \"logfood_agent_dev\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3c48cf1-9901-4764-be98-99092ac4142d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "944439bd-53a5-4f8b-a2b2-0cad24b4e397",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Deploy UC Model Version with Endpoint Source Tagging"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d19ccb4574f4ca6a01c1c2a06efe35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-ae4fd991-bde7-4ebe-aebe-07c4a2565a20/lib/python3.12/site-packages/databricks/agents/deployments.py:641: UserWarning: This endpoint is being deployed without a feedback model, which has been deprecated.\nFor more information, see: https://docs.databricks.com/aws/en/generative-ai/agent-framework/feedback-model\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n    Deployment of ankit_yadav.demo.logfood_agent_dev version 1 initiated.  This can take up to 15 minutes and the Review App & Query Endpoint will not work until this deployment finishes.\n\n    View status: https://fe-sandbox-serverless-9thezy.cloud.databricks.com/ml/endpoints/agents_ankit_yadav-demo-logfood_agent_dev/?o=7474651123329331\n    Review App: https://fe-sandbox-serverless-9thezy.cloud.databricks.com/ml/review-v2/df920ad2af9d41cfb878d272eba71636/chat?o=7474651123329331\n\nYou can refer back to the links above from the endpoint detail page at https://fe-sandbox-serverless-9thezy.cloud.databricks.com/ml/endpoints/agents_ankit_yadav-demo-logfood_agent_dev/?o=7474651123329331.\n\nTo set up monitoring for your deployed agent, see:\nhttps://docs.databricks.com/aws/en/mlflow3/genai/eval-monitor/production-monitoring\n"
     ]
    }
   ],
   "source": [
    "# from databricks import agents\n",
    "\n",
    "# agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version, tags={\"endpointSource\": \"docs\"})\n",
    "\n",
    "from databricks import agents\n",
    "\n",
    "deployment = agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    workload_type=\"CPU\",            # compute type\n",
    "    workload_size=\"Medium\",         # maps to 8–16 provisioned concurrency\n",
    "    tags={\"endpointSource\": \"docs\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c01c102-7010-487c-8a02-46f8e4883748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See Databricks documentation ([AWS](https://docs.databricks.com/en/generative-ai/deploy-agent.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/deploy-agent))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6d84f92-8cb3-4942-a495-2c639e6aefe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ce0c4e3-1dc2-424d-954e-0c0f370d2570",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Agent Prediction for Declining Revenue Analysis"
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "from agent_dev import AGENT\n",
    "\n",
    "# TODO: Replace this placeholder `input_example` with a domain-specific prompt for your agent.\n",
    "input_example = {\"input\": [{\"role\": \"user\", \"content\": \"Which use cases in the Evaluating or Confirming stage are associated with accounts that have shown declining revenue in the last 3 months? For these accounts, what's their primary product mix, and what recommendations would you make? Do this analysis for Josh Herman accounts.\"}]}\n",
    "\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2bf6e3a-e780-42f4-a159-0ecff64cbd5c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Analyze AI Adoption Impact on Account Performance"
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "#Not Correct\n",
    "from agent_dev import AGENT\n",
    "\n",
    "# TODO: Replace this placeholder `input_example` with a domain-specific prompt for your agent.\n",
    "input_example = {\"input\": [{\"role\": \"user\", \"content\": \"Compare accounts that adopted AI products in the last 6 months vs those that haven't. What's the difference in total revenue growth, use case progression speed, and workspace activity? Which AE's accounts show the strongest AI adoption?\"}]}\n",
    "\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ebfef4f-0602-4b1f-a6a2-49d2ca09bdcb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Health Score Prediction for Josh Herman Accounts"
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "#Write todos was not called, Incorrect \"All accounts have 0 active use‑cases and 0 days since the last use‑case update, giving them a perfect “Update Score” of 100 but an “Active UC Score” of 0\".\n",
    "from agent_dev import AGENT\n",
    "\n",
    "# TODO: Replace this placeholder `input_example` with a domain-specific prompt for your agent.\n",
    "input_example = {\"input\": [{\"role\": \"user\", \"content\": \"Create a health score for each Josh Herman accounts based on: (1) revenue trend last 90 days, (2) number of active use cases,(3) product diversity (# of different products used), and (4) days since last use case update. Rank accounts by health score and identify the top 5 at-risk accounts.\"}]}\n",
    "\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8970d3f1-cb1b-4485-bcef-7f1f60af02b6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Analyze Consumption Patterns for Josh Herman's Accounts"
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "from agent_dev import AGENT\n",
    "\n",
    "# TODO: Replace this placeholder `input_example` with a domain-specific prompt for your agent.\n",
    "input_example = {\"input\": [{\"role\": \"user\", \"content\": \"Analyze weekly consumption patterns over the last 12 weeks for Josh Herman accounts. Are there any day-of-week or week-of-month patterns? Which accounts show the most volatility, and what might explain it based on their use case stages?\"}]}\n",
    "\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "734cddbf-77f8-4d40-9e5f-64361bcc29a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Predicting AI adoption journey for SQL-only accounts"
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "from agent_dev import AGENT\n",
    "\n",
    "# TODO: Replace this placeholder `input_example` with a domain-specific prompt for your agent.\n",
    "input_example = {\"input\": [{\"role\": \"user\", \"content\": \"For accounts that eventually adopted AI products, what was their typical journey? What products did they start with? How long before AI adoption? What was their consumption pattern leading up to AI adoption? Use this to create a playbook for accelerating AI adoption in current SQL-only accounts.\"}]}\n",
    "\n",
    "AGENT.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Logfood_Agent_Dev",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}